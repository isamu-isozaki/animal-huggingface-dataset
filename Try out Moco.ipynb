{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f01aca",
   "metadata": {},
   "source": [
    "The main issue with clip is that it transfers the pose of the subject+it's too general and does not know which part of the image to focus on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7adda7f",
   "metadata": {},
   "source": [
    "For this, try out moco+retrieval. If this doesn't work think of retrieval with text+image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1dbf929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda\\envs\\diffusers\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\miniconda\\envs\\diffusers\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "D:\\miniconda\\envs\\diffusers\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2ee290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "# All rights reserved.\n",
    "\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import partial, reduce\n",
    "from operator import mul\n",
    "\n",
    "from timm.models.vision_transformer import VisionTransformer, _cfg\n",
    "from timm.models.layers.helpers import to_2tuple\n",
    "from timm.models.layers import PatchEmbed\n",
    "\n",
    "__all__ = [\n",
    "    'vit_small', \n",
    "    'vit_base',\n",
    "    'vit_conv_small',\n",
    "    'vit_conv_base',\n",
    "]\n",
    "\n",
    "\n",
    "class VisionTransformerMoCo(VisionTransformer):\n",
    "    def __init__(self, stop_grad_conv1=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Use fixed 2D sin-cos position embedding\n",
    "        self.num_tokens=1\n",
    "        \n",
    "        self.build_2d_sincos_position_embedding()\n",
    "        # weight initialization\n",
    "        for name, m in self.named_modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                if 'qkv' in name:\n",
    "                    # treat the weights of Q, K, V separately\n",
    "                    val = math.sqrt(6. / float(m.weight.shape[0] // 3 + m.weight.shape[1]))\n",
    "                    nn.init.uniform_(m.weight, -val, val)\n",
    "                else:\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "        nn.init.normal_(self.cls_token, std=1e-6)\n",
    "\n",
    "        if isinstance(self.patch_embed, PatchEmbed):\n",
    "            # xavier_uniform initialization\n",
    "            val = math.sqrt(6. / float(3 * reduce(mul, self.patch_embed.patch_size, 1) + self.embed_dim))\n",
    "            nn.init.uniform_(self.patch_embed.proj.weight, -val, val)\n",
    "            nn.init.zeros_(self.patch_embed.proj.bias)\n",
    "\n",
    "            if stop_grad_conv1:\n",
    "                self.patch_embed.proj.weight.requires_grad = False\n",
    "                self.patch_embed.proj.bias.requires_grad = False\n",
    "\n",
    "    def build_2d_sincos_position_embedding(self, temperature=10000.):\n",
    "        h, w = self.patch_embed.grid_size\n",
    "        grid_w = torch.arange(w, dtype=torch.float32)\n",
    "        grid_h = torch.arange(h, dtype=torch.float32)\n",
    "        grid_w, grid_h = torch.meshgrid(grid_w, grid_h)\n",
    "        assert self.embed_dim % 4 == 0, 'Embed dimension must be divisible by 4 for 2D sin-cos position embedding'\n",
    "        pos_dim = self.embed_dim // 4\n",
    "        omega = torch.arange(pos_dim, dtype=torch.float32) / pos_dim\n",
    "        omega = 1. / (temperature**omega)\n",
    "        out_w = torch.einsum('m,d->md', [grid_w.flatten(), omega])\n",
    "        out_h = torch.einsum('m,d->md', [grid_h.flatten(), omega])\n",
    "        pos_emb = torch.cat([torch.sin(out_w), torch.cos(out_w), torch.sin(out_h), torch.cos(out_h)], dim=1)[None, :, :]\n",
    "\n",
    "        assert self.num_tokens == 1, 'Assuming one and only one token, [cls]'\n",
    "        pe_token = torch.zeros([1, 1, self.embed_dim], dtype=torch.float32)\n",
    "        self.pos_embed = nn.Parameter(torch.cat([pe_token, pos_emb], dim=1))\n",
    "        self.pos_embed.requires_grad = False\n",
    "\n",
    "\n",
    "class ConvStem(nn.Module):\n",
    "    \"\"\" \n",
    "    ConvStem, from Early Convolutions Help Transformers See Better, Tete et al. https://arxiv.org/abs/2106.14881\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768, norm_layer=None, flatten=True):\n",
    "        super().__init__()\n",
    "\n",
    "        assert patch_size == 16, 'ConvStem only supports patch size of 16'\n",
    "        assert embed_dim % 8 == 0, 'Embed dimension must be divisible by 8 for ConvStem'\n",
    "\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.grid_size = (img_size[0] // patch_size[0], img_size[1] // patch_size[1])\n",
    "        self.num_patches = self.grid_size[0] * self.grid_size[1]\n",
    "        self.flatten = flatten\n",
    "\n",
    "        # build stem, similar to the design in https://arxiv.org/abs/2106.14881\n",
    "        stem = []\n",
    "        input_dim, output_dim = 3, embed_dim // 8\n",
    "        for l in range(4):\n",
    "            stem.append(nn.Conv2d(input_dim, output_dim, kernel_size=3, stride=2, padding=1, bias=False))\n",
    "            stem.append(nn.BatchNorm2d(output_dim))\n",
    "            stem.append(nn.ReLU(inplace=True))\n",
    "            input_dim = output_dim\n",
    "            output_dim *= 2\n",
    "        stem.append(nn.Conv2d(input_dim, embed_dim, kernel_size=1))\n",
    "        self.proj = nn.Sequential(*stem)\n",
    "\n",
    "        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        x = self.proj(x)\n",
    "        if self.flatten:\n",
    "            x = x.flatten(2).transpose(1, 2)  # BCHW -> BNC\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def vit_small(**kwargs):\n",
    "    model = VisionTransformerMoCo(\n",
    "        patch_size=16, embed_dim=384, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    return model\n",
    "\n",
    "def vit_base(**kwargs):\n",
    "    model = VisionTransformerMoCo(\n",
    "        patch_size=16, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    return model\n",
    "\n",
    "def vit_conv_small(**kwargs):\n",
    "    # minus one ViT block\n",
    "    model = VisionTransformerMoCo(\n",
    "        patch_size=16, embed_dim=384, depth=11, num_heads=12, mlp_ratio=4, qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6), embed_layer=ConvStem, **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    return model\n",
    "\n",
    "def vit_conv_base(**kwargs):\n",
    "    # minus one ViT block\n",
    "    model = VisionTransformerMoCo(\n",
    "        patch_size=16, embed_dim=768, depth=11, num_heads=12, mlp_ratio=4, qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6), embed_layer=ConvStem, **kwargs)\n",
    "    model.default_cfg = _cfg()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da2db8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "# All rights reserved.\n",
    "\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MoCo(nn.Module):\n",
    "    \"\"\"\n",
    "    Build a MoCo model with a base encoder, a momentum encoder, and two MLPs\n",
    "    https://arxiv.org/abs/1911.05722\n",
    "    \"\"\"\n",
    "    def __init__(self, base_encoder, dim=256, mlp_dim=4096, T=1.0):\n",
    "        \"\"\"\n",
    "        dim: feature dimension (default: 256)\n",
    "        mlp_dim: hidden dimension in MLPs (default: 4096)\n",
    "        T: softmax temperature (default: 1.0)\n",
    "        \"\"\"\n",
    "        super(MoCo, self).__init__()\n",
    "\n",
    "        self.T = T\n",
    "\n",
    "        # build encoders\n",
    "        self.base_encoder = base_encoder(num_classes=mlp_dim)\n",
    "        self.momentum_encoder = base_encoder(num_classes=mlp_dim)\n",
    "\n",
    "        self._build_projector_and_predictor_mlps(dim, mlp_dim)\n",
    "\n",
    "        for param_b, param_m in zip(self.base_encoder.parameters(), self.momentum_encoder.parameters()):\n",
    "            param_m.data.copy_(param_b.data)  # initialize\n",
    "            param_m.requires_grad = False  # not update by gradient\n",
    "\n",
    "    def _build_mlp(self, num_layers, input_dim, mlp_dim, output_dim, last_bn=True):\n",
    "        mlp = []\n",
    "        for l in range(num_layers):\n",
    "            dim1 = input_dim if l == 0 else mlp_dim\n",
    "            dim2 = output_dim if l == num_layers - 1 else mlp_dim\n",
    "\n",
    "            mlp.append(nn.Linear(dim1, dim2, bias=False))\n",
    "\n",
    "            if l < num_layers - 1:\n",
    "                mlp.append(nn.BatchNorm1d(dim2))\n",
    "                mlp.append(nn.ReLU(inplace=True))\n",
    "            elif last_bn:\n",
    "                # follow SimCLR's design: https://github.com/google-research/simclr/blob/master/model_util.py#L157\n",
    "                # for simplicity, we further removed gamma in BN\n",
    "                mlp.append(nn.BatchNorm1d(dim2, affine=False))\n",
    "\n",
    "        return nn.Sequential(*mlp)\n",
    "    def _build_projector_and_predictor_mlps(self, dim, mlp_dim):\n",
    "        pass\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _update_momentum_encoder(self, m):\n",
    "        \"\"\"Momentum update of the momentum encoder\"\"\"\n",
    "        for param_b, param_m in zip(self.base_encoder.parameters(), self.momentum_encoder.parameters()):\n",
    "            param_m.data = param_m.data * m + param_b.data * (1. - m)\n",
    "\n",
    "    def contrastive_loss(self, q, k):\n",
    "        # normalize\n",
    "        q = nn.functional.normalize(q, dim=1)\n",
    "        k = nn.functional.normalize(k, dim=1)\n",
    "        # gather all targets\n",
    "        k = concat_all_gather(k)\n",
    "        # Einstein sum is more intuitive\n",
    "        logits = torch.einsum('nc,mc->nm', [q, k]) / self.T\n",
    "        N = logits.shape[0]  # batch size per GPU\n",
    "        labels = (torch.arange(N, dtype=torch.long) + N * torch.distributed.get_rank()).cuda()\n",
    "        return nn.CrossEntropyLoss()(logits, labels) * (2 * self.T)\n",
    "\n",
    "    def forward(self, x1, x2, m):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            x1: first views of images\n",
    "            x2: second views of images\n",
    "            m: moco momentum\n",
    "        Output:\n",
    "            loss\n",
    "        \"\"\"\n",
    "\n",
    "        # compute features\n",
    "        q1 = self.predictor(self.base_encoder(x1))\n",
    "        q2 = self.predictor(self.base_encoder(x2))\n",
    "\n",
    "        with torch.no_grad():  # no gradient\n",
    "            self._update_momentum_encoder(m)  # update the momentum encoder\n",
    "\n",
    "            # compute momentum features as targets\n",
    "            k1 = self.momentum_encoder(x1)\n",
    "            k2 = self.momentum_encoder(x2)\n",
    "\n",
    "        return self.contrastive_loss(q1, k2) + self.contrastive_loss(q2, k1)\n",
    "\n",
    "\n",
    "class MoCo_ResNet(MoCo):\n",
    "    def _build_projector_and_predictor_mlps(self, dim, mlp_dim):\n",
    "        hidden_dim = self.base_encoder.fc.weight.shape[1]\n",
    "        del self.base_encoder.fc, self.momentum_encoder.fc # remove original fc layer\n",
    "\n",
    "        # projectors\n",
    "        self.base_encoder.fc = self._build_mlp(2, hidden_dim, mlp_dim, dim)\n",
    "        self.momentum_encoder.fc = self._build_mlp(2, hidden_dim, mlp_dim, dim)\n",
    "\n",
    "        # predictor\n",
    "        self.predictor = self._build_mlp(2, dim, mlp_dim, dim, False)\n",
    "\n",
    "\n",
    "class MoCo_ViT(MoCo):\n",
    "    def _build_projector_and_predictor_mlps(self, dim, mlp_dim):\n",
    "        hidden_dim = self.base_encoder.head.weight.shape[1]\n",
    "        del self.base_encoder.head, self.momentum_encoder.head # remove original fc layer\n",
    "\n",
    "        # projectors\n",
    "        self.base_encoder.head = self._build_mlp(3, hidden_dim, mlp_dim, dim)\n",
    "        self.momentum_encoder.head = self._build_mlp(3, hidden_dim, mlp_dim, dim)\n",
    "\n",
    "        # predictor\n",
    "        self.predictor = self._build_mlp(2, dim, mlp_dim, dim)\n",
    "\n",
    "\n",
    "# utils\n",
    "@torch.no_grad()\n",
    "def concat_all_gather(tensor):\n",
    "    \"\"\"\n",
    "    Performs all_gather operation on the provided tensors.\n",
    "    *** Warning ***: torch.distributed.all_gather has no gradient.\n",
    "    \"\"\"\n",
    "    tensors_gather = [torch.ones_like(tensor)\n",
    "        for _ in range(torch.distributed.get_world_size())]\n",
    "    torch.distributed.all_gather(tensors_gather, tensor, async_op=False)\n",
    "\n",
    "    output = torch.cat(tensors_gather, dim=0)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d2553cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda\\envs\\diffusers\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "model = MoCo_ViT(\n",
    "    partial(vit_base, stop_grad_conv1=False),\n",
    "    256, 4096, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78de4e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MoCo_ViT(\n",
       "  (base_encoder): VisionTransformerMoCo(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=4096, bias=False)\n",
       "      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Linear(in_features=4096, out_features=256, bias=False)\n",
       "      (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (momentum_encoder): VisionTransformerMoCo(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=4096, bias=False)\n",
       "      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Linear(in_features=4096, out_features=256, bias=False)\n",
       "      (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (predictor): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=4096, bias=False)\n",
       "    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=4096, out_features=256, bias=False)\n",
       "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82d9d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = torch.load(\"moco-v3-models/vit-b-300ep.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf3faca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_state_dict = {}\n",
    "for key in model_state_dict['state_dict']:\n",
    "    updated_state_dict[key[7:]]=model_state_dict['state_dict'][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "199e1c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(updated_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7d1e892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MoCo_ViT(\n",
       "  (base_encoder): VisionTransformerMoCo(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=4096, bias=False)\n",
       "      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Linear(in_features=4096, out_features=256, bias=False)\n",
       "      (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (momentum_encoder): VisionTransformerMoCo(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=4096, bias=False)\n",
       "      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Linear(in_features=4096, out_features=256, bias=False)\n",
       "      (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (predictor): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=4096, bias=False)\n",
       "    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=4096, out_features=256, bias=False)\n",
       "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8b1eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "059d26a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81f035ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MoCo_ViT(\n",
       "  (base_encoder): VisionTransformerMoCo(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=4096, bias=False)\n",
       "      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Linear(in_features=4096, out_features=256, bias=False)\n",
       "      (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (momentum_encoder): VisionTransformerMoCo(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=4096, bias=False)\n",
       "      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "      (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Linear(in_features=4096, out_features=256, bias=False)\n",
       "      (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (predictor): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=4096, bias=False)\n",
       "    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=4096, out_features=256, bias=False)\n",
       "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a252a590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=768, out_features=4096, bias=False)\n",
       "  (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "  (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): Linear(in_features=4096, out_features=256, bias=False)\n",
       "  (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_encoder.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc5d62d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageOps\n",
    "image1 = Image.open(\"frida/0.jpg\")\n",
    "image1 = ImageOps.exif_transpose(image1)\n",
    "image1 = image1.resize((224, 224))\n",
    "image1 = normalize(transforms.ToTensor()(image1))\n",
    "image2 = Image.open(\"random_animals/dog.jpg\")\n",
    "image2 = ImageOps.exif_transpose(image2)\n",
    "image2 = image2.resize((224, 224))\n",
    "image2 = normalize(transforms.ToTensor()(image2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "62f95bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.base_encoder.head = torch.nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0bc9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_features = model.base_encoder(image1[None].to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "949ef863",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2_features = model.base_encoder(image2[None].to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1dd3bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_features = image1_features/ torch.linalg.norm(image1_features, dim=-1, keepdim=True)\n",
    "image2_features = image2_features/ torch.linalg.norm(image2_features, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ccac3ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image2_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "16eb8c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07062746"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(image1_features.cpu().detach().numpy()[0], image2_features.cpu().detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3cb9f01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(image1_features.cpu().detach().numpy()[0], image1_features.cpu().detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c34143a",
   "metadata": {},
   "source": [
    "Not too bad. Let's see if we can finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2f8b1e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from diffusers.models.retriever import get_dataset_with_emb_from_model, map_img_to_model_feature\n",
    "from transformers import CLIPImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ce14202",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = CLIPImageProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c493178a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPImageProcessor {\n",
       "  \"crop_size\": {\n",
       "    \"height\": 224,\n",
       "    \"width\": 224\n",
       "  },\n",
       "  \"do_center_crop\": true,\n",
       "  \"do_convert_rgb\": true,\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.48145466,\n",
       "    0.4578275,\n",
       "    0.40821073\n",
       "  ],\n",
       "  \"image_processor_type\": \"CLIPImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.26862954,\n",
       "    0.26130258,\n",
       "    0.27577711\n",
       "  ],\n",
       "  \"resample\": 3,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"shortest_edge\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f603444f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration Isamu136--big-animal-dataset-with-l14-e6365e3df6462f2d\n",
      "Found cached dataset parquet (D:/cache/huggingface/datasets/Isamu136___parquet/Isamu136--big-animal-dataset-with-l14-e6365e3df6462f2d/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca45004d155148dca8fe9d297f08d6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Isamu136/big-animal-dataset-with-l14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ffd469bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'caption', 'l14_embeddings'],\n",
       "        num_rows: 62149\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.rename_column(\"embeddings\", \"l14_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "07c60bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb133bae465a4f118c8ecbb7d7993053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62149 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1 get_dataset_with_emb_from_model(dataset, model.base_encoder, feature_extractor, index_na     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\personal_projects\\diffusion\\diffusers\\src\\diffusers\\models\\retriever.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span> in                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_dataset_with_emb_from_model</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197    </span>image_embeddings = image_embeddings[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, ...]                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> image_embeddings                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_dataset_with_emb_from_model</span>(dataset, model, feature_extractor, device=<span style=\"color: #808000; text-decoration-color: #808000\">\"cuda\"</span>, im   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>200 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> dataset.map(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span> example: {index_name: map_img_to_model_feature(model, feat   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\personal_projects\\diffusion\\datasets\\src\\datasets\\dataset_dict.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">816</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">map</span>                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 813       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> cache_file_names <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 814          </span>cache_file_names = {k: <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>}                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 815       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> DatasetDict(                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 816 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>{                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 817             </span>k: dataset.map(                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 818                </span>function=function,                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 819                </span>with_indices=with_indices,                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\personal_projects\\diffusion\\datasets\\src\\datasets\\dataset_dict.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">817</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;dictcomp&gt;</span>           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 814          </span>cache_file_names = {k: <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>}                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 815       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> DatasetDict(                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 816          </span>{                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 817 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>k: dataset.map(                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 818                </span>function=function,                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 819                </span>with_indices=with_indices,                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 820                </span>with_rank=with_rank,                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\personal_projects\\diffusion\\datasets\\src\\datasets\\arrow_dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2826</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">map</span>                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2823       </span>disable_tqdm = <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> logging.is_progress_bar_enabled()                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2824       </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2825       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> num_proc <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> num_proc == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>2826 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._map_single(                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2827             </span>function=function,                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2828             </span>with_indices=with_indices,                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2829             </span>with_rank=with_rank,                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\personal_projects\\diffusion\\datasets\\src\\datasets\\arrow_dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">562</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 559       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 560          </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>: <span style=\"color: #808000; text-decoration-color: #808000\">\"Dataset\"</span> = kwargs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">\"self\"</span>)                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 561       # apply actual function</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 562 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>out: Union[<span style=\"color: #808000; text-decoration-color: #808000\">\"Dataset\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"DatasetDict\"</span>] = func(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **kwargs)                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 563       </span>datasets: List[<span style=\"color: #808000; text-decoration-color: #808000\">\"Dataset\"</span>] = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(out.values()) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(out, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">dict</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> [ou  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 564       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> dataset <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> datasets:                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 565          # Remove task templates if a column mapping of the template is no longer val</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\personal_projects\\diffusion\\datasets\\src\\datasets\\arrow_dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">529</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 526          </span><span style=\"color: #808000; text-decoration-color: #808000\">\"output_all_columns\"</span>: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._output_all_columns,                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 527       </span>}                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 528       # apply actual function</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 529 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>out: Union[<span style=\"color: #808000; text-decoration-color: #808000\">\"Dataset\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"DatasetDict\"</span>] = func(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **kwargs)                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 530       </span>datasets: List[<span style=\"color: #808000; text-decoration-color: #808000\">\"Dataset\"</span>] = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(out.values()) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(out, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">dict</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> [ou  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 531       # re-apply format to the output</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 532       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> dataset <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> datasets:                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\personal_projects\\diffusion\\datasets\\src\\datasets\\fingerprint.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">480</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">477          </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">478          # Call actual function</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">479          </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>480 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>out = func(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **kwargs)                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">481          </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">482          # Update fingerprint of in-place transforms + update in-place history of tra</span>   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">483 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\personal_projects\\diffusion\\datasets\\src\\datasets\\arrow_dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3232</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_map_single</span>        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3229             </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3230             </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> batched:                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3231                </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i, example <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> pbar:                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>3232 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>example = apply_function_on_filtered_inputs(example, i, offset=o  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3233                   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> update_data:                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3234                      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> i == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3235                         </span>buf_writer, writer, tmp_file = init_buffer_and_writer()   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\personal_projects\\diffusion\\datasets\\src\\datasets\\arrow_dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3123</span> in                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">apply_function_on_filtered_inputs</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3120             </span>additional_args += (effective_indices,)                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3121          </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> with_rank:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3122             </span>additional_args += (rank,)                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>3123 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3124          </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(processed_inputs, LazyDict):                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3125             </span>processed_inputs = {                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3126                </span>k: v <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k, v <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> processed_inputs.data.items() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> k <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> processed  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\personal_projects\\diffusion\\diffusers\\src\\diffusers\\models\\retriever.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;lambda&gt;</span>       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197    </span>image_embeddings = image_embeddings[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, ...]                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> image_embeddings                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_dataset_with_emb_from_model</span>(dataset, model, feature_extractor, device=<span style=\"color: #808000; text-decoration-color: #808000\">\"cuda\"</span>, im   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>200 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> dataset.map(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span> example: {index_name: map_img_to_model_feature(model, feat   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\personal_projects\\diffusion\\diffusers\\src\\diffusers\\models\\retriever.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">194</span> in                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">map_img_to_model_feature</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">191       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> image.mode == <span style=\"color: #808000; text-decoration-color: #808000\">\"RGB\"</span>:                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">192          </span>imgs[i] = image.convert(<span style=\"color: #808000; text-decoration-color: #808000\">\"RGB\"</span>)                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">193    </span>imgs = normalize_images(imgs)                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>retrieved_images = preprocess_images(imgs, feature_extractor).to(device)               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">195    </span>image_embeddings = model(retrieved_images)                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">196    </span>image_embeddings = image_embeddings / torch.linalg.norm(image_embeddings, dim=-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, ke   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197    </span>image_embeddings = image_embeddings[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, ...]                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\personal_projects\\diffusion\\diffusers\\src\\diffusers\\pipelines\\rdm\\pipeline_rdm.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">44</span> in       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">preprocess_images</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 41 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">      </span><span style=\"color: #808000; text-decoration-color: #808000\">:obj:`torch.FloatTensor`: A batch of tensors.</span>                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 42 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 43    </span>images = [np.array(image) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> image <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> images]                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 44 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>images = [(image + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1.</span>) / <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2.</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> image <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> images]                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 45    </span>images = feature_extractor(images, return_tensors=<span style=\"color: #808000; text-decoration-color: #808000\">\"pt\"</span>).pixel_values                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 46    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> images                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 47 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\personal_projects\\diffusion\\diffusers\\src\\diffusers\\pipelines\\rdm\\pipeline_rdm.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">44</span> in       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 41 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">      </span><span style=\"color: #808000; text-decoration-color: #808000\">:obj:`torch.FloatTensor`: A batch of tensors.</span>                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 42 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 43    </span>images = [np.array(image) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> image <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> images]                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 44 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>images = [(image + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1.</span>) / <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2.</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> image <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> images]                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 45    </span>images = feature_extractor(images, return_tensors=<span style=\"color: #808000; text-decoration-color: #808000\">\"pt\"</span>).pixel_values                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 46    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> images                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 47 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1 get_dataset_with_emb_from_model(dataset, model.base_encoder, feature_extractor, index_na     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[33mD:\\personal_projects\\diffusion\\diffusers\\src\\diffusers\\models\\retriever.py\u001b[0m:\u001b[94m200\u001b[0m in                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92mget_dataset_with_emb_from_model\u001b[0m                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m   \u001b[0mimage_embeddings = image_embeddings[\u001b[94mNone\u001b[0m, ...]                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mreturn\u001b[0m image_embeddings                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m199 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mget_dataset_with_emb_from_model\u001b[0m(dataset, model, feature_extractor, device=\u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m, im   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m200 \u001b[2m   \u001b[0m\u001b[94mreturn\u001b[0m dataset.map(\u001b[94mlambda\u001b[0m example: {index_name: map_img_to_model_feature(model, feat   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m201 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[33mD:\\personal_projects\\diffusion\\datasets\\src\\datasets\\dataset_dict.py\u001b[0m:\u001b[94m816\u001b[0m in \u001b[92mmap\u001b[0m                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 813 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m cache_file_names \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 814 \u001b[0m\u001b[2m         \u001b[0mcache_file_names = {k: \u001b[94mNone\u001b[0m \u001b[94mfor\u001b[0m k \u001b[95min\u001b[0m \u001b[96mself\u001b[0m}                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 815 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m DatasetDict(                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 816 \u001b[2m         \u001b[0m{                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 817 \u001b[0m\u001b[2m            \u001b[0mk: dataset.map(                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 818 \u001b[0m\u001b[2m               \u001b[0mfunction=function,                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 819 \u001b[0m\u001b[2m               \u001b[0mwith_indices=with_indices,                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[33mD:\\personal_projects\\diffusion\\datasets\\src\\datasets\\dataset_dict.py\u001b[0m:\u001b[94m817\u001b[0m in \u001b[92m<dictcomp>\u001b[0m           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 814 \u001b[0m\u001b[2m         \u001b[0mcache_file_names = {k: \u001b[94mNone\u001b[0m \u001b[94mfor\u001b[0m k \u001b[95min\u001b[0m \u001b[96mself\u001b[0m}                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 815 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m DatasetDict(                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 816 \u001b[0m\u001b[2m         \u001b[0m{                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 817 \u001b[2m            \u001b[0mk: dataset.map(                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 818 \u001b[0m\u001b[2m               \u001b[0mfunction=function,                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 819 \u001b[0m\u001b[2m               \u001b[0mwith_indices=with_indices,                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 820 \u001b[0m\u001b[2m               \u001b[0mwith_rank=with_rank,                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[33mD:\\personal_projects\\diffusion\\datasets\\src\\datasets\\arrow_dataset.py\u001b[0m:\u001b[94m2826\u001b[0m in \u001b[92mmap\u001b[0m                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2823 \u001b[0m\u001b[2m      \u001b[0mdisable_tqdm = \u001b[95mnot\u001b[0m logging.is_progress_bar_enabled()                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2824 \u001b[0m\u001b[2m      \u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2825 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m num_proc \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m num_proc == \u001b[94m1\u001b[0m:                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m2826 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._map_single(                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2827 \u001b[0m\u001b[2m            \u001b[0mfunction=function,                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2828 \u001b[0m\u001b[2m            \u001b[0mwith_indices=with_indices,                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2829 \u001b[0m\u001b[2m            \u001b[0mwith_rank=with_rank,                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[33mD:\\personal_projects\\diffusion\\datasets\\src\\datasets\\arrow_dataset.py\u001b[0m:\u001b[94m562\u001b[0m in \u001b[92mwrapper\u001b[0m             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 559 \u001b[0m\u001b[2m      \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 560 \u001b[0m\u001b[2m         \u001b[0m\u001b[96mself\u001b[0m: \u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m = kwargs.pop(\u001b[33m\"\u001b[0m\u001b[33mself\u001b[0m\u001b[33m\"\u001b[0m)                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 561 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# apply actual function\u001b[0m                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 562 \u001b[2m      \u001b[0mout: Union[\u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mDatasetDict\u001b[0m\u001b[33m\"\u001b[0m] = func(\u001b[96mself\u001b[0m, *args, **kwargs)                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 563 \u001b[0m\u001b[2m      \u001b[0mdatasets: List[\u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[96mlist\u001b[0m(out.values()) \u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(out, \u001b[96mdict\u001b[0m) \u001b[94melse\u001b[0m [ou  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 564 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mfor\u001b[0m dataset \u001b[95min\u001b[0m datasets:                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 565 \u001b[0m\u001b[2m         \u001b[0m\u001b[2m# Remove task templates if a column mapping of the template is no longer val\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[33mD:\\personal_projects\\diffusion\\datasets\\src\\datasets\\arrow_dataset.py\u001b[0m:\u001b[94m529\u001b[0m in \u001b[92mwrapper\u001b[0m             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 526 \u001b[0m\u001b[2m         \u001b[0m\u001b[33m\"\u001b[0m\u001b[33moutput_all_columns\u001b[0m\u001b[33m\"\u001b[0m: \u001b[96mself\u001b[0m._output_all_columns,                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 527 \u001b[0m\u001b[2m      \u001b[0m}                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 528 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# apply actual function\u001b[0m                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 529 \u001b[2m      \u001b[0mout: Union[\u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mDatasetDict\u001b[0m\u001b[33m\"\u001b[0m] = func(\u001b[96mself\u001b[0m, *args, **kwargs)                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 530 \u001b[0m\u001b[2m      \u001b[0mdatasets: List[\u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[96mlist\u001b[0m(out.values()) \u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(out, \u001b[96mdict\u001b[0m) \u001b[94melse\u001b[0m [ou  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 531 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# re-apply format to the output\u001b[0m                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 532 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mfor\u001b[0m dataset \u001b[95min\u001b[0m datasets:                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[33mD:\\personal_projects\\diffusion\\datasets\\src\\datasets\\fingerprint.py\u001b[0m:\u001b[94m480\u001b[0m in \u001b[92mwrapper\u001b[0m               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m477 \u001b[0m\u001b[2m         \u001b[0m                                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m478 \u001b[0m\u001b[2m         \u001b[0m\u001b[2m# Call actual function\u001b[0m                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m479 \u001b[0m\u001b[2m         \u001b[0m                                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m480 \u001b[2m         \u001b[0mout = func(\u001b[96mself\u001b[0m, *args, **kwargs)                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m481 \u001b[0m\u001b[2m         \u001b[0m                                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m482 \u001b[0m\u001b[2m         \u001b[0m\u001b[2m# Update fingerprint of in-place transforms + update in-place history of tra\u001b[0m   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m483 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[33mD:\\personal_projects\\diffusion\\datasets\\src\\datasets\\arrow_dataset.py\u001b[0m:\u001b[94m3232\u001b[0m in \u001b[92m_map_single\u001b[0m        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3229 \u001b[0m\u001b[2m            \u001b[0m)                                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3230 \u001b[0m\u001b[2m            \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m batched:                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3231 \u001b[0m\u001b[2m               \u001b[0m\u001b[94mfor\u001b[0m i, example \u001b[95min\u001b[0m pbar:                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m3232 \u001b[2m                  \u001b[0mexample = apply_function_on_filtered_inputs(example, i, offset=o  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3233 \u001b[0m\u001b[2m                  \u001b[0m\u001b[94mif\u001b[0m update_data:                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3234 \u001b[0m\u001b[2m                     \u001b[0m\u001b[94mif\u001b[0m i == \u001b[94m0\u001b[0m:                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3235 \u001b[0m\u001b[2m                        \u001b[0mbuf_writer, writer, tmp_file = init_buffer_and_writer()   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[33mD:\\personal_projects\\diffusion\\datasets\\src\\datasets\\arrow_dataset.py\u001b[0m:\u001b[94m3123\u001b[0m in                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92mapply_function_on_filtered_inputs\u001b[0m                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3120 \u001b[0m\u001b[2m            \u001b[0madditional_args += (effective_indices,)                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3121 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m with_rank:                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3122 \u001b[0m\u001b[2m            \u001b[0madditional_args += (rank,)                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m3123 \u001b[2m         \u001b[0mprocessed_inputs = function(*fn_args, *additional_args, **fn_kwargs)          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3124 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(processed_inputs, LazyDict):                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3125 \u001b[0m\u001b[2m            \u001b[0mprocessed_inputs = {                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3126 \u001b[0m\u001b[2m               \u001b[0mk: v \u001b[94mfor\u001b[0m k, v \u001b[95min\u001b[0m processed_inputs.data.items() \u001b[94mif\u001b[0m k \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m processed  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[33mD:\\personal_projects\\diffusion\\diffusers\\src\\diffusers\\models\\retriever.py\u001b[0m:\u001b[94m200\u001b[0m in \u001b[92m<lambda>\u001b[0m       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m   \u001b[0mimage_embeddings = image_embeddings[\u001b[94mNone\u001b[0m, ...]                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mreturn\u001b[0m image_embeddings                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m199 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mget_dataset_with_emb_from_model\u001b[0m(dataset, model, feature_extractor, device=\u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m, im   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m200 \u001b[2m   \u001b[0m\u001b[94mreturn\u001b[0m dataset.map(\u001b[94mlambda\u001b[0m example: {index_name: map_img_to_model_feature(model, feat   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m201 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[33mD:\\personal_projects\\diffusion\\diffusers\\src\\diffusers\\models\\retriever.py\u001b[0m:\u001b[94m194\u001b[0m in                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92mmap_img_to_model_feature\u001b[0m                                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m191 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m image.mode == \u001b[33m\"\u001b[0m\u001b[33mRGB\u001b[0m\u001b[33m\"\u001b[0m:                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m192 \u001b[0m\u001b[2m         \u001b[0mimgs[i] = image.convert(\u001b[33m\"\u001b[0m\u001b[33mRGB\u001b[0m\u001b[33m\"\u001b[0m)                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m193 \u001b[0m\u001b[2m   \u001b[0mimgs = normalize_images(imgs)                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m194 \u001b[2m   \u001b[0mretrieved_images = preprocess_images(imgs, feature_extractor).to(device)               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m195 \u001b[0m\u001b[2m   \u001b[0mimage_embeddings = model(retrieved_images)                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m196 \u001b[0m\u001b[2m   \u001b[0mimage_embeddings = image_embeddings / torch.linalg.norm(image_embeddings, dim=-\u001b[94m1\u001b[0m, ke   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m   \u001b[0mimage_embeddings = image_embeddings[\u001b[94mNone\u001b[0m, ...]                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[33mD:\\personal_projects\\diffusion\\diffusers\\src\\diffusers\\pipelines\\rdm\\pipeline_rdm.py\u001b[0m:\u001b[94m44\u001b[0m in       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92mpreprocess_images\u001b[0m                                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 41 \u001b[0m\u001b[2;33m      \u001b[0m\u001b[33m:obj:`torch.FloatTensor`: A batch of tensors.\u001b[0m                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 42 \u001b[0m\u001b[2;33m   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 43 \u001b[0m\u001b[2m   \u001b[0mimages = [np.array(image) \u001b[94mfor\u001b[0m image \u001b[95min\u001b[0m images]                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 44 \u001b[2m   \u001b[0mimages = [(image + \u001b[94m1.\u001b[0m) / \u001b[94m2.\u001b[0m \u001b[94mfor\u001b[0m image \u001b[95min\u001b[0m images]                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m   \u001b[0mimages = feature_extractor(images, return_tensors=\u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m).pixel_values                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mreturn\u001b[0m images                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 47 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[33mD:\\personal_projects\\diffusion\\diffusers\\src\\diffusers\\pipelines\\rdm\\pipeline_rdm.py\u001b[0m:\u001b[94m44\u001b[0m in       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m<listcomp>\u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 41 \u001b[0m\u001b[2;33m      \u001b[0m\u001b[33m:obj:`torch.FloatTensor`: A batch of tensors.\u001b[0m                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 42 \u001b[0m\u001b[2;33m   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 43 \u001b[0m\u001b[2m   \u001b[0mimages = [np.array(image) \u001b[94mfor\u001b[0m image \u001b[95min\u001b[0m images]                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 44 \u001b[2m   \u001b[0mimages = [(image + \u001b[94m1.\u001b[0m) / \u001b[94m2.\u001b[0m \u001b[94mfor\u001b[0m image \u001b[95min\u001b[0m images]                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m   \u001b[0mimages = feature_extractor(images, return_tensors=\u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m).pixel_values                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mreturn\u001b[0m images                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 47 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_dataset_with_emb_from_model(dataset, model.base_encoder, feature_extractor, index_name=\"moco_vitb_imagenet_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63b88d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
